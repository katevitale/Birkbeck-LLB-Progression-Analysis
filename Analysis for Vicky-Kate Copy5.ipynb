{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "\n",
    "# Start here once given anonymized csvs.\n",
    "\n",
    "###########################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import LLB_custom_scripts_mac\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through anonymized files and save the dataframes \n",
    "# of progression and module files in separate dictionaries.\n",
    "# Also make a dictionary with the number of assessments in \n",
    "# each module, each year.\n",
    "\n",
    "# Define paths for locating anonymized csvs.\n",
    "anon_module_csv_path = (\"/Users/Kate/Desktop/Vicky project/\"\n",
    "                        \"Data/anonymized module csvs/\")\n",
    "\n",
    "anon_progression_csv_path = (\"/Users/Kate/Desktop/Vicky project/\"\n",
    "                            \"Data/anonymized progression csvs/\")\n",
    "\n",
    "progression_files = {}\n",
    "module_files = {}\n",
    "n_assessments_module_dict = {}\n",
    "\n",
    "for filename in os.listdir(anon_module_csv_path):\n",
    "    if filename == '.DS_Store': \n",
    "        continue\n",
    "    else:\n",
    "        # Convert csv to dataframe and store in a dictionary.\n",
    "        module_name = f'{filename}'.split('.')[0]\n",
    "        module_files[module_name] = pd.read_csv(\n",
    "            anon_module_csv_path + f'{filename}')\n",
    "        module_files[module_name].set_index('SPR Code', inplace=True)\n",
    "        num_assessments = module_files[module_name].columns[-1].split(' ')[1]\n",
    "        n_assessments_module_dict[module_name] = num_assessments\n",
    "for filename in os.listdir(anon_progression_csv_path):\n",
    "    if filename == '.DS_Store': \n",
    "        continue\n",
    "    else:\n",
    "        # Convert csv to dataframe and store in a dictionary.\n",
    "        progression_files[f'{filename}'.split('.')[0]] = pd.read_csv(\n",
    "            anon_progression_csv_path + f'{filename}')\n",
    "        progression_files[f'{filename}'.split('.')[0]].set_index(\n",
    "            'SPR Code', inplace=True)\n",
    "global module_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "\n",
    "# Below are code snippets that I will turn into functions for batch\n",
    "# analysis once I've gotten the snippets figured out and have \n",
    "# planned the batch analysis process. \n",
    "#\n",
    "# Each snippet is for a single module.\n",
    "#\n",
    "# Each snippet should be written as efficiently as possible.\n",
    "\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_progression = '201718_PROGRESSION_FT'\n",
    "example_module = '201718_CONTRACT_assessment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which assessments were failed by students who failed\n",
    "# a module and calculate the proportionate share each assessment\n",
    "# contributed to students' module failures.\n",
    "\n",
    "# Make a df to store assessment results\n",
    "num_assessments = int(n_assessments_module_dict[example_module])\n",
    "df_column_names = [f'Assessment {a} P or F' \\\n",
    "                   for a in range(1, num_assessments + 1)]\n",
    "df_idx = module_files[example_module].index\n",
    "P_F_status = pd.DataFrame(data=[], index=df_idx, \\\n",
    "                             columns = df_column_names)\n",
    "\n",
    "# Populate df\n",
    "for index, row in module_files[example_module].iterrows():\n",
    "    for a in range(1,num_assessments+1):\n",
    "        if row[f'Assessment {str(a)} Grade'] in ['P','LP']:\n",
    "            P_F_status.at[index, f'Assessment {str(a)} P or F'] = 'P'\n",
    "        elif row[f'Assessment {str(a)} Grade'] in ['F', 'W', 'FR', 'DR']:\n",
    "            P_F_status.at[index, f'Assessment {str(a)} P or F'] = 'F'\n",
    "        \n",
    "\n",
    "new_df = P_F_status.join(module_files[example_module])\n",
    "\n",
    "#new_df.groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if each student sat each failed assessment\n",
    "# \n",
    "# The below is for an example module. \n",
    "# Make sub-size dataframe called submission_status\n",
    "num_assessments = int(n_assessments_module_dict[example_module])\n",
    "column_names = \\\n",
    "    [f'Assessment {a} Submission' for a in range(1, num_assessments + 1)]\n",
    "idx = module_files[example_module].index\n",
    "submission_status = pd.DataFrame(data=[], index=idx, columns = column_names)\n",
    "\n",
    "for index, row in module_files[example_module].iterrows():\n",
    "    for assessment in range(1,num_assessments+1):\n",
    "        if row[f'Assessment {assessment} Grade'] not in ['P','LP']:\n",
    "            try:\n",
    "                if int(float(row[f'Assessment {assessment} Mark'])) == 0:\n",
    "                    submission_status.at[index, f'Assessment {assessment} Submission'] = \\\n",
    "                    'Non-submission'\n",
    "                else:\n",
    "                    submission_status.at[index, f'Assessment {assessment} Submission'] = \\\n",
    "                    'Failed submission'\n",
    "            except:\n",
    "                continue\n",
    "submission_status.join(module_files[example_module])\n",
    "# Then, can join onto existing df and make a count? Or make new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many failed assessment 1\n",
    "\n",
    "failed_a1 = len(P_F_status.loc[P_F_status['Assessment 1 P or F'] \\\n",
    "                                                       == 'F'])\n",
    "\n",
    "# how many failed assessment 2\n",
    "\n",
    "failed_a2 = len(P_F_status.loc[P_F_status['Assessment 2 P or F'] \\\n",
    "                                                        == 'F'])\n",
    "\n",
    "# how many got no grade at all?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Will need to deal with marks being float sometimes\n",
    "int(float('33.0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Make module summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of students each module's assessment and store in module\n",
    "# summary file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each assessment and reassessment table, add variable\n",
    "# for whether progressed after reassessment or retake\n",
    "# if applicable. Calculate percentage of students retaking\n",
    "# and progressing at the end of retake. Ditto for reassess.\n",
    "# Store in module summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each assessment file, add a column for EACH ASSESSMENT \n",
    "# retake verus reassess (FR or DR) versus NA, \\ \n",
    "# then count re-assess versus retake and percentage\n",
    "# and store percentage in module summary file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at re-assessment period for the same year, and \n",
    "# mark whether each student is DR or FR for each \n",
    "# assignment, based on previous assessment's data\n",
    "# then use groupby to determine stats on passing module\n",
    "# (sum function for P versus F?) \n",
    "# Store in module summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each assessment and reassessment, \n",
    "# add a column for non-submission \n",
    "# versus failed submission versus NA, then count each\n",
    "# overall, and for each individual assessment/reassessment\n",
    "# store in module summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of related module tables \n",
    "# initial assessment, reassessment, retake)\n",
    "module_name = example_module\n",
    "if module_name.split('_')[0] == '201718':\n",
    "    retake_name = None\n",
    "else:\n",
    "    retake_name = module_name.split('_')[0][:2] + \\\n",
    "        str(int(module_name.split('_')[0][2:4]) + 1) + \\\n",
    "        str(int(module_name.split('_')[0][4:]) + 1) + '_' + \\\n",
    "        module_name.split('_')[1] + '_' + module_name.split('_')[2]\n",
    "\n",
    "# Determine if module ...\n",
    "for index, row in module_files[module_name].iterrows():\n",
    "    if row['Grade'] == 'F':\n",
    "\n",
    "#         if retake_name != None:\n",
    "#             if int(module_files[retake_name].at[index, 'Attempt']) == \\\n",
    "#                 int(row['Attempt']) + 1:\n",
    "#                 # student retook in the following period\n",
    "#                 repeat_status.at[index, 'Overall'] = 'Retake'\n",
    "            \n",
    "        # elif terminated?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
